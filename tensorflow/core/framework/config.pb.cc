// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/framework/config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/framework/config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* GPUOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GPUOptions_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ConfigProto_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_DeviceCountEntry_descriptor_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/framework/config.proto");
  GOOGLE_CHECK(file != NULL);
  GPUOptions_descriptor_ = file->message_type(0);
  static const int GPUOptions_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, per_process_gpu_memory_fraction_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, allocator_type_),
  };
  GPUOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GPUOptions_descriptor_,
      GPUOptions::default_instance_,
      GPUOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(GPUOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _is_default_instance_));
  ConfigProto_descriptor_ = file->message_type(1);
  static const int ConfigProto_offsets_[9] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_count_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, intra_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, inter_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, use_per_session_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, placement_period_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_filters_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, gpu_options_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, allow_soft_placement_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, log_device_placement_),
  };
  ConfigProto_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ConfigProto_descriptor_,
      ConfigProto::default_instance_,
      ConfigProto_offsets_,
      -1,
      -1,
      -1,
      sizeof(ConfigProto),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _is_default_instance_));
  ConfigProto_DeviceCountEntry_descriptor_ = ConfigProto_descriptor_->nested_type(0);
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GPUOptions_descriptor_, &GPUOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ConfigProto_descriptor_, &ConfigProto::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
        ConfigProto_DeviceCountEntry_descriptor_,
        ::google::protobuf::internal::MapEntry<
            ::std::string,
            ::google::protobuf::int32,
            ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
            ::google::protobuf::internal::WireFormatLite::TYPE_INT32,
            0>::CreateDefaultInstance(
                ConfigProto_DeviceCountEntry_descriptor_));
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  delete GPUOptions::default_instance_;
  delete GPUOptions_reflection_;
  delete ConfigProto::default_instance_;
  delete ConfigProto_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n&tensorflow/core/framework/config.proto"
    "\022\ntensorflow\"M\n\nGPUOptions\022\'\n\037per_proces"
    "s_gpu_memory_fraction\030\001 \001(\001\022\026\n\016allocator"
    "_type\030\002 \001(\t\"\211\003\n\013ConfigProto\022>\n\014device_co"
    "unt\030\001 \003(\0132(.tensorflow.ConfigProto.Devic"
    "eCountEntry\022$\n\034intra_op_parallelism_thre"
    "ads\030\002 \001(\005\022$\n\034inter_op_parallelism_thread"
    "s\030\005 \001(\005\022\037\n\027use_per_session_threads\030\t \001(\010"
    "\022\030\n\020placement_period\030\003 \001(\005\022\026\n\016device_fil"
    "ters\030\004 \003(\t\022+\n\013gpu_options\030\006 \001(\0132\026.tensor"
    "flow.GPUOptions\022\034\n\024allow_soft_placement\030"
    "\007 \001(\010\022\034\n\024log_device_placement\030\010 \001(\010\0322\n\020D"
    "eviceCountEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 "
    "\001(\005:\0028\001b\006proto3", 535);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/framework/config.proto", &protobuf_RegisterTypes);
  GPUOptions::default_instance_ = new GPUOptions();
  ConfigProto::default_instance_ = new ConfigProto();
  GPUOptions::default_instance_->InitAsDefaultInstance();
  ConfigProto::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fframework_2fconfig_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fframework_2fconfig_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fframework_2fconfig_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fframework_2fconfig_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#ifndef _MSC_VER
const int GPUOptions::kPerProcessGpuMemoryFractionFieldNumber;
const int GPUOptions::kAllocatorTypeFieldNumber;
#endif  // !_MSC_VER

GPUOptions::GPUOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GPUOptions)
}

void GPUOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GPUOptions::GPUOptions(const GPUOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions)
}

void GPUOptions::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

GPUOptions::~GPUOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions)
  SharedDtor();
}

void GPUOptions::SharedDtor() {
  allocator_type_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void GPUOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GPUOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GPUOptions_descriptor_;
}

const GPUOptions& GPUOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

GPUOptions* GPUOptions::default_instance_ = NULL;

GPUOptions* GPUOptions::New(::google::protobuf::Arena* arena) const {
  GPUOptions* n = new GPUOptions;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void GPUOptions::Clear() {
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

bool GPUOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GPUOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double per_process_gpu_memory_fraction = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &per_process_gpu_memory_fraction_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_allocator_type;
        break;
      }

      // optional string allocator_type = 2;
      case 2: {
        if (tag == 18) {
         parse_allocator_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_allocator_type()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->allocator_type().data(), this->allocator_type().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.GPUOptions.allocator_type"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GPUOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GPUOptions)
  return false;
#undef DO_
}

void GPUOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->per_process_gpu_memory_fraction(), output);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->allocator_type(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GPUOptions)
}

::google::protobuf::uint8* GPUOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->per_process_gpu_memory_fraction(), target);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->allocator_type(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions)
  return target;
}

int GPUOptions::ByteSize() const {
  int total_size = 0;

  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    total_size += 1 + 8;
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->allocator_type());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GPUOptions::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GPUOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GPUOptions>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void GPUOptions::MergeFrom(const GPUOptions& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.per_process_gpu_memory_fraction() != 0) {
    set_per_process_gpu_memory_fraction(from.per_process_gpu_memory_fraction());
  }
  if (from.allocator_type().size() > 0) {

    allocator_type_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.allocator_type_);
  }
}

void GPUOptions::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GPUOptions::CopyFrom(const GPUOptions& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GPUOptions::IsInitialized() const {

  return true;
}

void GPUOptions::Swap(GPUOptions* other) {
  if (other == this) return;
  InternalSwap(other);
}
void GPUOptions::InternalSwap(GPUOptions* other) {
  std::swap(per_process_gpu_memory_fraction_, other->per_process_gpu_memory_fraction_);
  allocator_type_.Swap(&other->allocator_type_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GPUOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GPUOptions_descriptor_;
  metadata.reflection = GPUOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GPUOptions

// optional double per_process_gpu_memory_fraction = 1;
void GPUOptions::clear_per_process_gpu_memory_fraction() {
  per_process_gpu_memory_fraction_ = 0;
}
 double GPUOptions::per_process_gpu_memory_fraction() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
  return per_process_gpu_memory_fraction_;
}
 void GPUOptions::set_per_process_gpu_memory_fraction(double value) {
  
  per_process_gpu_memory_fraction_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
}

// optional string allocator_type = 2;
void GPUOptions::clear_allocator_type() {
  allocator_type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& GPUOptions::allocator_type() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void GPUOptions::set_allocator_type(const ::std::string& value) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value, size_t size) {
  
  allocator_type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.GPUOptions.allocator_type)
}
 ::std::string* GPUOptions::mutable_allocator_type() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* GPUOptions::release_allocator_type() {
  
  return allocator_type_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void GPUOptions::set_allocated_allocator_type(::std::string* allocator_type) {
  if (allocator_type != NULL) {
    
  } else {
    
  }
  allocator_type_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), allocator_type);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.GPUOptions.allocator_type)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#ifndef _MSC_VER
const int ConfigProto::kDeviceCountFieldNumber;
const int ConfigProto::kIntraOpParallelismThreadsFieldNumber;
const int ConfigProto::kInterOpParallelismThreadsFieldNumber;
const int ConfigProto::kUsePerSessionThreadsFieldNumber;
const int ConfigProto::kPlacementPeriodFieldNumber;
const int ConfigProto::kDeviceFiltersFieldNumber;
const int ConfigProto::kGpuOptionsFieldNumber;
const int ConfigProto::kAllowSoftPlacementFieldNumber;
const int ConfigProto::kLogDevicePlacementFieldNumber;
#endif  // !_MSC_VER

ConfigProto::ConfigProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ConfigProto)
}

void ConfigProto::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  gpu_options_ = const_cast< ::tensorflow::GPUOptions*>(&::tensorflow::GPUOptions::default_instance());
}

ConfigProto::ConfigProto(const ConfigProto& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ConfigProto)
}

void ConfigProto::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  device_count_.SetAssignDescriptorCallback(
      protobuf_AssignDescriptorsOnce);
  device_count_.SetEntryDescriptor(
      &::tensorflow::ConfigProto_DeviceCountEntry_descriptor_);
  intra_op_parallelism_threads_ = 0;
  inter_op_parallelism_threads_ = 0;
  use_per_session_threads_ = false;
  placement_period_ = 0;
  gpu_options_ = NULL;
  allow_soft_placement_ = false;
  log_device_placement_ = false;
}

ConfigProto::~ConfigProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ConfigProto)
  SharedDtor();
}

void ConfigProto::SharedDtor() {
  if (this != default_instance_) {
    delete gpu_options_;
  }
}

void ConfigProto::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ConfigProto::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ConfigProto_descriptor_;
}

const ConfigProto& ConfigProto::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fframework_2fconfig_2eproto();
  return *default_instance_;
}

ConfigProto* ConfigProto::default_instance_ = NULL;

ConfigProto* ConfigProto::New(::google::protobuf::Arena* arena) const {
  ConfigProto* n = new ConfigProto;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ConfigProto::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<ConfigProto*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(intra_op_parallelism_threads_, inter_op_parallelism_threads_);
  ZR_(placement_period_, allow_soft_placement_);
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
  log_device_placement_ = false;

#undef ZR_HELPER_
#undef ZR_

  device_count_.Clear();
  device_filters_.Clear();
}

bool ConfigProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ConfigProto)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // map<string, int32> device_count = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_count:
          ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry(device_count_.NewEntry());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
              input, entry.get()));
          (*mutable_device_count())[entry->key()] = *entry->mutable_value();
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry->key().data(), entry->key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.DeviceCountEntry.key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_device_count;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(16)) goto parse_intra_op_parallelism_threads;
        break;
      }

      // optional int32 intra_op_parallelism_threads = 2;
      case 2: {
        if (tag == 16) {
         parse_intra_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &intra_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_placement_period;
        break;
      }

      // optional int32 placement_period = 3;
      case 3: {
        if (tag == 24) {
         parse_placement_period:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &placement_period_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        break;
      }

      // repeated string device_filters = 4;
      case 4: {
        if (tag == 34) {
         parse_device_filters:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_device_filters()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device_filters(this->device_filters_size() - 1).data(),
            this->device_filters(this->device_filters_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.device_filters"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        if (input->ExpectTag(40)) goto parse_inter_op_parallelism_threads;
        break;
      }

      // optional int32 inter_op_parallelism_threads = 5;
      case 5: {
        if (tag == 40) {
         parse_inter_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inter_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_gpu_options;
        break;
      }

      // optional .tensorflow.GPUOptions gpu_options = 6;
      case 6: {
        if (tag == 50) {
         parse_gpu_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_gpu_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(56)) goto parse_allow_soft_placement;
        break;
      }

      // optional bool allow_soft_placement = 7;
      case 7: {
        if (tag == 56) {
         parse_allow_soft_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &allow_soft_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(64)) goto parse_log_device_placement;
        break;
      }

      // optional bool log_device_placement = 8;
      case 8: {
        if (tag == 64) {
         parse_log_device_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &log_device_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_use_per_session_threads;
        break;
      }

      // optional bool use_per_session_threads = 9;
      case 9: {
        if (tag == 72) {
         parse_use_per_session_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_per_session_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ConfigProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ConfigProto)
  return false;
#undef DO_
}

void ConfigProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
          1, *entry, output);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->intra_op_parallelism_threads(), output);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->placement_period(), output);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->device_filters(i), output);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->inter_op_parallelism_threads(), output);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->gpu_options_, output);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->allow_soft_placement(), output);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(8, this->log_device_placement(), output);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->use_per_session_threads(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ConfigProto)
}

::google::protobuf::uint8* ConfigProto::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      target = ::google::protobuf::internal::WireFormatLite::
          WriteMessageNoVirtualToArray(
              1, *entry, target);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->intra_op_parallelism_threads(), target);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->placement_period(), target);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->device_filters(i), target);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(5, this->inter_op_parallelism_threads(), target);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        6, *this->gpu_options_, target);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->allow_soft_placement(), target);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(8, this->log_device_placement(), target);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->use_per_session_threads(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ConfigProto)
  return target;
}

int ConfigProto::ByteSize() const {
  int total_size = 0;

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->intra_op_parallelism_threads());
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->inter_op_parallelism_threads());
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    total_size += 1 + 1;
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->placement_period());
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->gpu_options_);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    total_size += 1 + 1;
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    total_size += 1 + 1;
  }

  // map<string, int32> device_count = 1;
  total_size += 1 * this->device_count_size();
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      total_size += ::google::protobuf::internal::WireFormatLite::
          MessageSizeNoVirtual(*entry);
    }
  }

  // repeated string device_filters = 4;
  total_size += 1 * this->device_filters_size();
  for (int i = 0; i < this->device_filters_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->device_filters(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ConfigProto::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ConfigProto* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ConfigProto>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void ConfigProto::MergeFrom(const ConfigProto& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  device_count_.MergeFrom(from.device_count_);
  device_filters_.MergeFrom(from.device_filters_);
  if (from.intra_op_parallelism_threads() != 0) {
    set_intra_op_parallelism_threads(from.intra_op_parallelism_threads());
  }
  if (from.inter_op_parallelism_threads() != 0) {
    set_inter_op_parallelism_threads(from.inter_op_parallelism_threads());
  }
  if (from.use_per_session_threads() != 0) {
    set_use_per_session_threads(from.use_per_session_threads());
  }
  if (from.placement_period() != 0) {
    set_placement_period(from.placement_period());
  }
  if (from.has_gpu_options()) {
    mutable_gpu_options()->::tensorflow::GPUOptions::MergeFrom(from.gpu_options());
  }
  if (from.allow_soft_placement() != 0) {
    set_allow_soft_placement(from.allow_soft_placement());
  }
  if (from.log_device_placement() != 0) {
    set_log_device_placement(from.log_device_placement());
  }
}

void ConfigProto::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ConfigProto::CopyFrom(const ConfigProto& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ConfigProto::IsInitialized() const {

  return true;
}

void ConfigProto::Swap(ConfigProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ConfigProto::InternalSwap(ConfigProto* other) {
  device_count_.Swap(&other->device_count_);
  std::swap(intra_op_parallelism_threads_, other->intra_op_parallelism_threads_);
  std::swap(inter_op_parallelism_threads_, other->inter_op_parallelism_threads_);
  std::swap(use_per_session_threads_, other->use_per_session_threads_);
  std::swap(placement_period_, other->placement_period_);
  device_filters_.UnsafeArenaSwap(&other->device_filters_);
  std::swap(gpu_options_, other->gpu_options_);
  std::swap(allow_soft_placement_, other->allow_soft_placement_);
  std::swap(log_device_placement_, other->log_device_placement_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ConfigProto::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ConfigProto_descriptor_;
  metadata.reflection = ConfigProto_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ConfigProto

// map<string, int32> device_count = 1;
int ConfigProto::device_count_size() const {
  return device_count_.size();
}
void ConfigProto::clear_device_count() {
  device_count_.Clear();
}
 const ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >&
ConfigProto::device_count() const {
  // @@protoc_insertion_point(field_map:tensorflow.ConfigProto.device_count)
  return device_count_.GetMap();
}
 ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >*
ConfigProto::mutable_device_count() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.ConfigProto.device_count)
  return device_count_.MutableMap();
}

// optional int32 intra_op_parallelism_threads = 2;
void ConfigProto::clear_intra_op_parallelism_threads() {
  intra_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::intra_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.intra_op_parallelism_threads)
  return intra_op_parallelism_threads_;
}
 void ConfigProto::set_intra_op_parallelism_threads(::google::protobuf::int32 value) {
  
  intra_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.intra_op_parallelism_threads)
}

// optional int32 inter_op_parallelism_threads = 5;
void ConfigProto::clear_inter_op_parallelism_threads() {
  inter_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::inter_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.inter_op_parallelism_threads)
  return inter_op_parallelism_threads_;
}
 void ConfigProto::set_inter_op_parallelism_threads(::google::protobuf::int32 value) {
  
  inter_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.inter_op_parallelism_threads)
}

// optional bool use_per_session_threads = 9;
void ConfigProto::clear_use_per_session_threads() {
  use_per_session_threads_ = false;
}
 bool ConfigProto::use_per_session_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.use_per_session_threads)
  return use_per_session_threads_;
}
 void ConfigProto::set_use_per_session_threads(bool value) {
  
  use_per_session_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.use_per_session_threads)
}

// optional int32 placement_period = 3;
void ConfigProto::clear_placement_period() {
  placement_period_ = 0;
}
 ::google::protobuf::int32 ConfigProto::placement_period() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.placement_period)
  return placement_period_;
}
 void ConfigProto::set_placement_period(::google::protobuf::int32 value) {
  
  placement_period_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.placement_period)
}

// repeated string device_filters = 4;
int ConfigProto::device_filters_size() const {
  return device_filters_.size();
}
void ConfigProto::clear_device_filters() {
  device_filters_.Clear();
}
 const ::std::string& ConfigProto::device_filters(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.device_filters)
  return device_filters_.Get(index);
}
 ::std::string* ConfigProto::mutable_device_filters(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.device_filters)
  return device_filters_.Mutable(index);
}
 void ConfigProto::set_device_filters(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.device_filters)
  device_filters_.Mutable(index)->assign(value);
}
 void ConfigProto::set_device_filters(int index, const char* value) {
  device_filters_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::set_device_filters(int index, const char* value, size_t size) {
  device_filters_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.ConfigProto.device_filters)
}
 ::std::string* ConfigProto::add_device_filters() {
  return device_filters_.Add();
}
 void ConfigProto::add_device_filters(const ::std::string& value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value, size_t size) {
  device_filters_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.ConfigProto.device_filters)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
ConfigProto::device_filters() const {
  // @@protoc_insertion_point(field_list:tensorflow.ConfigProto.device_filters)
  return device_filters_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
ConfigProto::mutable_device_filters() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ConfigProto.device_filters)
  return &device_filters_;
}

// optional .tensorflow.GPUOptions gpu_options = 6;
bool ConfigProto::has_gpu_options() const {
  return !_is_default_instance_ && gpu_options_ != NULL;
}
void ConfigProto::clear_gpu_options() {
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
}
const ::tensorflow::GPUOptions& ConfigProto::gpu_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.gpu_options)
  return gpu_options_ != NULL ? *gpu_options_ : *default_instance_->gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::mutable_gpu_options() {
  
  if (gpu_options_ == NULL) {
    gpu_options_ = new ::tensorflow::GPUOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.gpu_options)
  return gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::release_gpu_options() {
  
  ::tensorflow::GPUOptions* temp = gpu_options_;
  gpu_options_ = NULL;
  return temp;
}
void ConfigProto::set_allocated_gpu_options(::tensorflow::GPUOptions* gpu_options) {
  delete gpu_options_;
  gpu_options_ = gpu_options;
  if (gpu_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ConfigProto.gpu_options)
}

// optional bool allow_soft_placement = 7;
void ConfigProto::clear_allow_soft_placement() {
  allow_soft_placement_ = false;
}
 bool ConfigProto::allow_soft_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.allow_soft_placement)
  return allow_soft_placement_;
}
 void ConfigProto::set_allow_soft_placement(bool value) {
  
  allow_soft_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.allow_soft_placement)
}

// optional bool log_device_placement = 8;
void ConfigProto::clear_log_device_placement() {
  log_device_placement_ = false;
}
 bool ConfigProto::log_device_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.log_device_placement)
  return log_device_placement_;
}
 void ConfigProto::set_log_device_placement(bool value) {
  
  log_device_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.log_device_placement)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
